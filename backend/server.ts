import express, { type Request, type Response, type NextFunction } from 'express';
import type { Graph } from '../graphSchema';

const app = express();
const PORT = process.env.PORT ? parseInt(process.env.PORT, 10) : 5000;
const LLM_API_KEY = process.env.OPENAI_API_KEY;

const SYSTEM_PROMPT = `
You are a system design diagram generator.

Your task:
- Convert the user's description into a system design graph.
- Output ONLY valid JSON.
- Do NOT include explanations, comments, or markdown.

Rules:
- Each node must have a unique "id" and a human-readable "label".
- Edges must reference node ids using "source" and "target".
- Keep the graph simple and minimal.
- Use short, clear labels.

Output format:
{
  "nodes": [{ "id": "...", "label": "..." }],
  "edges": [{ "source": "...", "target": "..." }]
}
`.trim();

function isValidGraph(candidate: unknown): candidate is Graph {
  if (!candidate || typeof candidate !== 'object') {
    return false;
  }

  const g = candidate as { nodes?: unknown; edges?: unknown };

  if (!Array.isArray(g.nodes) || !Array.isArray(g.edges)) {
    return false;
  }

  const nodeIds = new Set<string>();

  for (const node of g.nodes) {
    if (
      !node ||
      typeof node !== 'object' ||
      typeof (node as any).id !== 'string' ||
      typeof (node as any).label !== 'string'
    ) {
      return false;
    }
    if (nodeIds.has((node as any).id)) {
      return false;
    }
    nodeIds.add((node as any).id);
  }

  for (const edge of g.edges) {
    if (
      !edge ||
      typeof edge !== 'object' ||
      typeof (edge as any).source !== 'string' ||
      typeof (edge as any).target !== 'string'
    ) {
      return false;
    }
  }

  return true;
}

// Enable CORS for frontend communication
app.use((req: Request, res: Response, next: NextFunction) => {
  res.header('Access-Control-Allow-Origin', '*');
  res.header('Access-Control-Allow-Methods', 'GET, POST, PUT, DELETE, OPTIONS');
  res.header('Access-Control-Allow-Headers', 'Content-Type');
  next();
});

app.use(express.json());

/**
 * GET /graph
 * Returns a static graph JSON conforming to the Graph schema.
 * Hardcoded data for testing frontend-backend communication.
 */
app.get('/graph', (_req: Request, res: Response) => {
  const staticGraph: Graph = {
    nodes: [
      { id: '1', label: 'Node A' },
      { id: '2', label: 'Node B' },
      { id: '3', label: 'Node S' },
    ],
    edges: [
      { source: '1', target: '2' },
      { source: '2', target: '3' },
    ],
  };

  res.json(staticGraph);
});

/**
 * POST /generate-graph
 * Accepts a user prompt and returns a graph JSON generated by an LLM.
 */
app.post('/generate-graph', async (req: Request, res: Response) => {
  const userPrompt = req.body?.prompt as string | undefined;

  if (!LLM_API_KEY) {
    res.status(500).json({ error: 'LLM API key is not configured' });
    return;
  }

  if (!userPrompt || typeof userPrompt !== 'string') {
    res.status(400).json({ error: 'Missing or invalid "prompt" in request body' });
    return;
  }

  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        Authorization: `Bearer ${LLM_API_KEY}`,
      },
      body: JSON.stringify({
        model: 'gpt-4.1-mini',
        messages: [
          { role: 'system', content: SYSTEM_PROMPT },
          { role: 'user', content: userPrompt },
        ],
        temperature: 0,
      }),
    });

    if (!response.ok) {
      const errorText = await response.text().catch(() => '');
      res.status(502).json({ error: 'LLM request failed', details: errorText });
      return;
    }

    const completion: any = await response.json();
    const content: string | undefined =
      completion?.choices?.[0]?.message?.content;

    if (!content || typeof content !== 'string') {
      res.status(502).json({ error: 'LLM returned an empty response' });
      return;
    }

    let parsed: unknown;
    try {
      parsed = JSON.parse(content);
    } catch (err) {
      res.status(502).json({ error: 'Failed to parse LLM JSON output' });
      return;
    }

    if (!isValidGraph(parsed)) {
      res.status(502).json({ error: 'LLM returned invalid graph structure' });
      return;
    }

    res.json(parsed);
  } catch (err) {
    res.status(500).json({ error: 'Unexpected error while generating graph' });
  }
});

const server = app.listen(PORT, () => {
  console.log(`Backend server running on http://localhost:${PORT}`);
  console.log(`Graph API available at http://localhost:${PORT}/graph`);
});

server.on('error', (err: NodeJS.ErrnoException) => {
  if (err.code === 'EADDRINUSE') {
    console.error(`Port ${PORT} is already in use. Please:`);
    console.error(`  1. Kill the process using port ${PORT}: lsof -ti:${PORT} | xargs kill`);
    console.error(`  2. Or use a different port: PORT=5001 npm run dev:backend`);
    process.exit(1);
  } else {
    throw err;
  }
});

 